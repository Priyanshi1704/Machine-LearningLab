{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJPUhXxA58wOMvVJObl0dp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanshi1704/Machine-LearningLab/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w24S4agzfmYt"
      },
      "source": [
        "normalization\n",
        "splitting\n",
        "hyper param \n",
        "training \n",
        "validation accuracy \n",
        "overfitting "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ySD4bt6B16"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaJ8GQT5fqJg"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itw3LQS4fqGD",
        "outputId": "0f10bdef-018c-4764-d55d-10861655a188"
      },
      "source": [
        "print(\"The dictonary keys are associated with data:\\n\", iris.keys())\n",
        "print(\"-\"*100)\n",
        "print(\"Data:\\n\", iris['data'])\n",
        "print(\"-\"*100)\n",
        "print(\"Name of the features (Independent features): \\n\", iris['feature_names'])\n",
        "print(\"-\"*100)\n",
        "print(\"Name of the dependent features: \", iris['target_names'])\n",
        "print(\"-\"*100)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dictonary keys are associated with data:\n",
            " dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Data:\n",
            " [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Name of the features (Independent features): \n",
            " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Name of the dependent features:  ['setosa' 'versicolor' 'virginica']\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6bB0IrYf1vn"
      },
      "source": [
        "1. Pre-process the data to use only 2 classes (Iris-Setosa and Iris-Versicolour)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjDSlLtLfqC6",
        "outputId": "99d48a4f-ad8f-42df-9094-fa682b972de6"
      },
      "source": [
        "y_actual = iris['target']\n",
        "y_actual = list(y_actual)\n",
        "counter_setosa = 0\n",
        "counter_versicolor = 0\n",
        "counter_virginica = 0\n",
        "for i in range(0,len(y_actual)):\n",
        "  if(y_actual[i]==0):\n",
        "    counter_setosa = counter_setosa  + 1 \n",
        "  if(y_actual[i]==1):\n",
        "    counter_versicolor = counter_versicolor + 1\n",
        "  if(y_actual[i]==2):\n",
        "    counter_virginica = counter_virginica + 1\n",
        "print(\"Total no of patterns in setosa class\",counter_setosa)\n",
        "print(\"Total no of patterns in setosa class\",counter_versicolor)\n",
        "print(\"Total no of patterns in setosa class\",counter_virginica)\n",
        "# take only first 100 patterns\n",
        "for i in range(0,50):\n",
        "  y_actual.remove(2)\n",
        "# covert it to an numpy array \n",
        "y_actual = np.array(y_actual)\n",
        "print(y_actual.shape[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no of patterns in setosa class 50\n",
            "Total no of patterns in setosa class 50\n",
            "Total no of patterns in setosa class 50\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok07BVpAfp_w",
        "outputId": "41681bc7-44bd-440a-9702-254c80b5aa68"
      },
      "source": [
        "# take only first 100 patterns for the binary classification \n",
        "features = list(iris['data'])\n",
        "print(len(features))\n",
        "del features[100:]\n",
        "print(len(features))\n",
        "features = np.array(features)\n",
        "print(\"No of the feature vectors: %d\"%features.shape[1])\n",
        "print(\"No of the Patterns: %d\"%features.shape[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n",
            "100\n",
            "No of the feature vectors: 4\n",
            "No of the Patterns: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awAH0cf8gELY"
      },
      "source": [
        "**2. Divide the dataset into train, validation and test with the dataset division ratio of your choice.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zisZC98fp8o",
        "outputId": "6a320712-df3b-4946-821b-9585b36fa363"
      },
      "source": [
        "# Train test validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "# train(70%), validation (10%), and test(20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,y_actual , test_size=0.3, random_state=random.randint(30,100))\n",
        "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.14, random_state=random.randint(30,100))\n",
        "print(\"Size of the train dataset:\",X_train.shape)\n",
        "print(\"Size of the validation dataset:\",X_validation.shape)\n",
        "print(\"Size of the test dataset:\",X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the train dataset: (70, 4)\n",
            "Size of the validation dataset: (5, 4)\n",
            "Size of the test dataset: (25, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcRv4EvcgbIu"
      },
      "source": [
        "\n",
        "# 3. Hyperparameter tuning on the validation set is required to be done. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIVCS2zgtyu"
      },
      "source": [
        "3.1. Sigmoid function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy0OxFrLfp5U"
      },
      "source": [
        "def sigmoid(x):\n",
        "  z = 1/(1 + np.exp(-x))\n",
        "  return z"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO3GW3Bngz_3"
      },
      "source": [
        "3.2. Gradient Decent Algorithem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qFEJUX2hM1W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA1o66YO-sf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "69079c1c-a1a4-46c8-9b5b-0c82429b1e2d"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "def gradient_descent(alpha, x, y, roh = 0.0001, max_iter=10):\n",
        "    converged = False\n",
        "    iter = 0\n",
        "    m = x.shape[0]\n",
        "    # Initial Weights\n",
        "    weight = np.ones(x.shape[1]+1)\n",
        "    hypo = np.ones(x.shape[1]+1)\n",
        "    random.seed(10) # for the same weight intialization\n",
        "    for i in range(0, x.shape[1]+1):\n",
        "      weight[i] = random.uniform(-0.3, 0.3)\n",
        "    # calculate the hypothesis value with the intial weights\n",
        "    for i in range(0, x.shape[0]):\n",
        "      rest = 0 \n",
        "      for j in range(1, x.shape[1]+1):\n",
        "        rest = rest + weight[]\n",
        "      hypo[i] = 1*weight[0] + rest\n",
        "    # implement log loss function of the error\n",
        "\n",
        "    while not converged:\n",
        "        error = 0\n",
        "        # Update the weight\n",
        "        temp_in = 0\n",
        "        temp_out = 0\n",
        "        for i in range(0,m): # fix the row\n",
        "          for j in range(0,x.shape[1]): # fix the column\n",
        "            temp_in = temp_in + weight[j+1]*x[i][j] #hypothesis calculation\n",
        "          temp_out = temp_out + (weight[0] + temp_in - y[j])*1\n",
        "        sum[0] = temp_out\n",
        "\n",
        "        for k in range(1,x.shape[1]):\n",
        "          temp_in = 0 \n",
        "          temp_out = 0\n",
        "          for i in range(0,m): # vary the row\n",
        "            for j in range(0,x.shape[1]):\n",
        "              temp_in = temp_in + weight[j+1]*x[i][j]\n",
        "            temp_out = temp_out + (weight[1] + temp_in - y[j])*x[i][k]\n",
        "          sum[k+1] = temp_out\n",
        "        # weight updatation\n",
        "        for j in range(0,x.shape[1]):\n",
        "          weight[j] = weight[j] - (alpha/m) * sum[j]\n",
        "        # Calculate the Mean Squared Error\n",
        "        for i in range(0,m): # vary the row\n",
        "          for j in range(0,x.shape[1]):\n",
        "            temp_in = temp_in + weight[j+1]*x[i][j]\n",
        "          error = error + (weight[0] + temp_in - y[i])**2 # total error\n",
        "        print(error)\n",
        "        if abs(total_error-error) <= ep:\n",
        "            print(total_error)\n",
        "            print(error)\n",
        "            print('Converged, iterations: ', iter, '!!!')\n",
        "            converged = True\n",
        "        total_error = error  # update error \n",
        "        iter += 1  # update iter\n",
        "        if iter == max_iter:\n",
        "            print('Max interactions exceeded!')\n",
        "            converged = True\n",
        "    return weight, error"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-6186d5654136>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    rest = rest + weight[]\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "1ygkQ5hQoszK",
        "outputId": "10ac39b1-be2b-4706-9b28-757ffc8ef085"
      },
      "source": [
        "priyanshi= gradient_descent(0.01, X_train, y_train, roh=0.00001, max_iter=10)\n",
        "print(priyanshi)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e999078b793a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpriyanshi\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpriyanshi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gradient_descent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ZSzQx9eyo03C",
        "outputId": "c304cdd4-4495-44aa-a7dc-ad373967ad5b"
      },
      "source": [
        "y_test = [1, 2, 3]\n",
        "y = y_test[0] # y = 1\n",
        "print(y[0]) # this line will fail"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b308364dbc29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# y = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this line will fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7WF8K4w0phK"
      },
      "source": [
        "alpha = [ 0.1, 0.001, 0.0001, 0.5, 1.0]\n",
        "mse = np.ones(5)\n",
        "weight = np.ones(14)\n",
        "for i in range(5):\n",
        "  weight,mse[i] = gradient_descent(alpha[i], X_train, y_train, ep=0, max_iter=1000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}